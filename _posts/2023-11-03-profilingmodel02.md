---
layout: single
title:  "Part 01. ì˜¨ë¼ì¸ ë©”ì‹œì§€ ì‘ì„±ì í”„ë¡œíŒŒì¼ë§ ëª¨ë¸ ê°œë°œ: ìì—°ì–´ ì „ì²˜ë¦¬ ë° ë³€ìˆ˜ ê°œë°œ"
categories: Project:Profileing_model
tag: [Feature Engineering, NLP]
---
<span style="color: #808080">#NLP #Feature Engineering #ìì—°ì–´ ê³„ëŸ‰ #ì¹´ì¹´ì˜¤í†¡ ì˜¤í”ˆì±„íŒ… ëŒ€í™” ë©”ì‹œì§€</span>
<hr>

{: .notice--primary} 
ğŸ’¡**í”„ë¡œì íŠ¸ ë°°ê²½**<br>

ê°œì¸ì •ë³´ ë³´í˜¸ì— ëŒ€í•œ ì‚¬íšŒì  ë¶„ìœ„ê¸°ì— ë”°ë¼ êµ¬ê¸€ ì¨ë“œíŒŒí‹° ì œê³µ ì¤‘ë‹¨, ì• í”Œ ì‚¬ìš©ì ì •ë³´ ê³µê°œ ì¤‘ë‹¨ ë“± ì‚¬ìš©ì ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ê²ƒì´ ì–´ë ¤ì›Œì§€ê³  ìˆìŒ. ìì‚¬ í”Œë«í¼ì— ê°€ì…í•œ ì‚¬ìš©ì ì™¸ ê³ ê° ë°ì´í„°ë¥¼ ì–»ëŠ” ê²ƒì€ ë”ìš± ì–´ë ¤ì›€.<br><br> 
ë§¥ë½ì •ë³´ë¥¼ í™œìš©í•œ ê³ ê° ë¶„ì„ ë° íƒ€ê²ŸíŒ… ì „ëµì— ëŒ€í•œ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆìœ¼ë‚˜ ëŒ€í‘œì ìœ¼ë¡œ ê³ ê°ì´ ìƒì‚°í•˜ëŠ” ë§¥ë½ì •ë³´ì¸ ì±„íŒ…, ë¦¬ë·°, í”¼ë“œ ë“±ìœ¼ë¡œ íŒŒì•…í•  ìˆ˜ ìˆëŠ” ì •ë³´ëŠ” ë§¤ìš° ì œí•œì ì„. íŠ¹íˆ, ì‚¬ìš©ìì˜ ì¸êµ¬í†µê³„ì  ì •ë³´ê°€ ì œê³µë˜ëŠ” ê²½ìš°ëŠ” ë§¤ìš° ë“œë¬¼ì–´ ê³ ê° ë¶„ì„ ë° íƒ€ê²ŸíŒ…ì— í™œìš©í•  ìˆ˜ ì—†ìŒ.<br><br> 
**ì±„íŒ…, ë¦¬ë·°, í”¼ë“œ ë“±ì—ì„œ ì‚¬ìš©ìì˜ ì¸êµ¬ í†µê³„ì  ì •ë³´ë¥¼ ì¶”ì •í•  ìˆ˜ ìˆë‹¤ë©´, ê³ ê° ë¶„ì„ ë° íƒ€ê²ŸíŒ…ì— í™œìš©í•  ìˆ˜ ìˆì„ ë¿ë§Œì•„ë‹ˆë¼ ì±—ë´‡/ë©”íƒ€ë²„ìŠ¤ ì„œë¹„ìŠ¤/CRM ì„œë¹„ìŠ¤ ë“±ì„ ê³ ë„í™”ì‹œí‚¬ ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë¨**<br><br>

{: .notice--primary} 
ğŸ¯**í”„ë¡œì íŠ¸ ëª©ì **<br>

ê³ ê°ì´ ì˜¨ë¼ì¸ ìƒì—ì„œ ìƒì‚°í•˜ëŠ” ë§¥ë½ì •ë³´(ì±„íŒ…, ë¦¬ë·°, í”¼ë“œ ë“±ì˜ í…ìŠ¤íŠ¸ ì •ë³´)ì—ì„œ ì‘ì„±ìì˜ ì¸êµ¬ í†µê³„ì  ì •ë³´(ì„±ë³„/ì—°ë ¹)ë¥¼ ì¶”ì •í•˜ëŠ” ì‘ì„±ì í”„ë¡œíŒŒì¼ë§ ëª¨ë¸ ê°œë°œ<br><br>


## ë³€ìˆ˜ ê°œë°œ ìš”ì•½<br>
**ë³€ìˆ˜ ê°œë°œì˜ í•„ìš”ì„±**
- ì¤„ì„ë§, ê³ ìœ  í‘œí˜„, ììŒ ë˜ëŠ” ëª¨ìŒìœ¼ë¡œë§Œ êµ¬ì„±ëœ ë¶ˆì™„ì „ í‘œí˜„, ë¬¸ì¥ê¸°í˜¸, íŠ¹ìˆ˜ê¸°í˜¸, ì´ëª¨ì§€ ë“±ì˜ í‘œí˜„ì€ **ê¸°ì¡´ì˜ NLP ì „ì²˜ë¦¬ ë° ì–¸ì–´ëª¨ë¸ì˜ Encoding ê³¼ì •ì—ì„œ ì œê±°ë¨**<br> í•˜ì§€ë§Œ, ì´ì™€ ê°™ì€ í‘œí˜„ë“¤ì´ **ë°œí™”ìì˜ ì„±ë³„/ì—°ë ¹ì— ëŒ€í•œ ì–¸ì–´ì  íŠ¹ì§•ìœ¼ë¡œ ë³´ì—¬ì§€ë¯€ë¡œ** ìƒê´€ê´€ê³„ íŒŒì•… ë° ëª¨ë¸ê°œë°œ ì‹œ ë°˜ì˜ì„ ìœ„í•œ feauture ê°œë°œ í•„ìš”
- ëª¨ë“  í‘œí˜„ì„ encodingí•˜ëŠ” ë°©ì‹ì€ ë¹„íš¨ìœ¨ì ì¼ë¿ë§Œ ì•„ë‹ˆë¼ ì‚¬ì „ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì— ì ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ **í‘œí˜„ì˜ íŠ¹ì„±ì„ ê³„ëŸ‰í™”í•œ ë³€ìˆ˜**ê°€ ìš”êµ¬ë¨
<br><br>

**ì¸ì‚¬ì´íŠ¸/ê°€ì„¤**
- ë³€í˜•ëœ í‘œí˜„ ë° íŠ¹ìˆ˜í‘œí˜„ ìì²´ê°€ ì‘ì„±ìì˜ ì¸êµ¬ í†µê³„ì  íŠ¹ì„±(ì„±ë³„/ì—°ë ¹)ê³¼ ì¤‘ìš”í•œ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŒ
1. Target feature(ì„±ë³„/ì—°ë ¹)ê³¼ í‘œí˜„ì˜ ë³€í˜•/íŠ¹ìˆ˜í‘œí˜„ ê°„ì˜ ìƒê´€ê´€ê³„ íŒŒì•…ì´ í•„ìš”<br>
â‡’ ìƒê´€ê´€ê³„ ë¶„ì„ì„ ìœ„í•œ ë³€ìˆ˜ ê°œë°œ í•„ìš”

2. ë³€í˜•ëœ í‘œí˜„ ë° íŠ¹ìˆ˜í•œ í‘œí˜„ì´ ì œê±°ë˜ì§€ ì•Šë„ë¡ ì „ì²˜ë¦¬ ìˆ˜í–‰
<br><br>

## ìì—°ì–´ ì „ì²˜ë¦¬


```python
import pandas as pd
import numpy as np
from tqdm import tqdm
tqdm.pandas()

import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
matplotlib.rcParams['font.family'] ='Malgun Gothic'
matplotlib.rcParams['axes.unicode_minus'] =False
```



    


- ê²°ì¸¡ê°’/ì¤‘ë³µê°’ ì œê±°


```python
import re

raw = df.shape[0]
print('- raw data: {:,}'.format(raw))


#ê²°ì¸¡ê°’ ì œê±°
print('- null data: {:,}'.format(df['contents'].isnull().sum()))
df = df.dropna() 
deleted_null = df.shape[0]



#ì¤‘ë³µ ì œê±°
df = df.drop_duplicates() 
deleted_dup = df.shape[0]
print('- duplicated data: {:,}'.format(deleted_null - deleted_dup))



#ë¬¸ì¥ ê¸¸ì´
df['contents_length'] = df['contents'].apply(lambda x : len(x))
```

    - raw data: 3,564,042
    - null data: 0
    - duplicated data: 0
    

### ì£¼ìš” ì´ëª¨ì§€ ë° íŠ¹ìˆ˜í‘œí˜„ í‘œì œí™”


```python
def emoji_lemmatization(sentence):
    heart_emoji = ['â™¡', 'â™¥', 'â¤', 'â¤ï¸', 'ğŸ§¡', 'ğŸ’›', 'ğŸ’š', 'ğŸ’™', 'ğŸ’œ', 'ğŸ’•'] #
    star_emoji = ['â˜†', 'â˜…', 'â­', 'ğŸŒŸ']
    kkk = ['ğ¨›', 'ğŒ…', 'â«¬', 'ãƒ²', 'åˆ', 'ã‰ª', 'ï½¦']
    Period = ['ã†', 'á†', 'ã†', 'â€¢', 'á†¢']
    quote = ['â€', 'â€˜', 'â€œ']
    ect = ['Â ', 'ã…¤']
    
    for i in range(len(sentence)):
        if sentence[i] in heart_emoji:
            sentence = sentence.replace(sentence[i], 'â™¥')
        elif sentence[i] in star_emoji:
            sentence = sentence.replace(sentence[i], 'â˜…')
        elif sentence[i] in kkk:
            sentence = sentence.replace(sentence[i], 'ã…‹')
        elif sentence[i] in Period:
            sentence = sentence.replace(sentence[i], '.')
        elif sentence[i] in quote:
            sentence = sentence.replace(sentence[i], '\'')
        elif sentence[i] in ect:
            sentence = sentence.replace(sentence[i], ' ')
        else:
            pass
    return(sentence)

def kkk_lemmatization(sentence):
    kkk2 =['ã…‹ê™¼Ìˆ', 'ã…‹Ì‘Ìˆ', 'ã…‹Ì†Ì', 'ã…‹ÌÌˆ', 'ã…‹ÌŠÌˆ', 'ã…‹Ì„Ìˆ', 'ã…‹Ì†Ìˆ', 'ã…‹ÌŠÌˆ', 'ã…‹ÌÌˆ', 'ã…‹Ì†Ì']
    
    for i in range(len(kkk2)):
        if kkk2[i] in sentence:
            sentence =  sentence.replace(kkk2[i], 'ã…‹')
        else:
            pass
    return(sentence)

text_sentence = 'â¤ğŸ§¡ğŸ’›í…ŒìŠ¤íŠ¸ğŸ’šğŸ’™ğŸ’œâ˜†ì…ë‹ˆë‹¤â˜…á†¢â­ ãƒ²ğ¨›ğŒ…â«¬ã…‹Ì„Ìˆã…‹ê™¼Ìˆã…‹Ì†Ìã…‹ÌÌˆã…‹ÌŠÌˆã…‹Ì„Ìˆã…‹ê™¼Ìˆã…‹Ì†Ìã…‹ÌÌˆã…‹ÌŠÌˆ'
text_sentence = emoji_lemmatization(text_sentence)
text_sentence = kkk_lemmatization(text_sentence)
text_sentence
```




    'â™¥â™¥â™¥í…ŒìŠ¤íŠ¸â™¥â™¥â™¥â˜…ì…ë‹ˆë‹¤â˜….â˜… ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹'




```python
df['contents'] = df['contents'].progress_apply(emoji_lemmatization)
df['contents'] = df['contents'].progress_apply(kkk_lemmatization)
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3564042/3564042 [05:13<00:00, 11354.18it/s]
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3564042/3564042 [00:10<00:00, 330031.43it/s]
    

### ë°˜ë³µë˜ëŠ” ë™ì¼ ìŒì ˆ í‘œì œí™” ì²˜ë¦¬


```python
def duplicated_spelling_reduction(sentence):
    reduced_spellings = []
    duplicated_num = 1
    for i in range(len(sentence)):
        spelling = sentence[i]
        try:
            previous_spelling = sentence[i-1]
            
        except:
            previous_spelling = 'first_spelling'
        
        if spelling == previous_spelling:
            duplicated_num += 1
        else:
            duplicated_num = 1
            pass
        
        if duplicated_num <= 5:
            reduced_spellings.append(spelling)
        else:
            pass      
        
    reduced_sentence = ''.join(reduced_spellings).replace('   ', ' ').replace('  ', ' ')
    return(reduced_sentence)

text_sentence = '    ì•ˆë…•ì•ˆë…• í—¤í—¤í—¤ ã…‹ã…‹ã…‹ã…‹ ã…ã…ã…ã…ã…ã…ã…ã… ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹'
duplicated_spelling_reduction(text_sentence)
```




    ' ì•ˆë…•ì•ˆë…• í—¤í—¤í—¤ ã…‹ã…‹ã…‹ã…‹ ã…ã…ã…ã…ã… ã…‹ã…‹ã…‹ã…‹ã…‹'




```python
df['contents'] = df['contents'].progress_apply(duplicated_spelling_reduction)
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3564042/3564042 [02:02<00:00, 29125.25it/s]
    

### ê³µë°±(ì¤‘ë³µ ë„ì–´ì“°ê¸°)/5ì–´ì ˆ ë¯¸ë§Œ ë¬¸ì¥ ì œê±°


```python
#ë„ì–´ì“°ê¸° ë¬¸ì¥ ì œê±°
df['contents'] = df['contents'].apply(lambda x : re.sub(r'\s', ' ', x))  #ë„ì–´ì“°ê¸° ì¤‘ë³µ ''ë¡œ ë³€ê²½
mask = df['contents'].isin([' '])
df = df[~mask].reset_index(drop = True) 
deleted_white = df.shape[0]
white = deleted_dup - deleted_white
print("- white space data: {:,}({}%)".format(white, round(white/deleted_dup*100, 2)))

#ì–´ì ˆ ì¹´ìš´íŒ…
df['word_bunch'] = df['contents'].apply(lambda x: len(x.split(' ')))


#5ì–´ì ˆ ë¯¸ë§Œ ë¬¸ì¥ ì œê±°
cutoff = df.loc[df['word_bunch'] < 5].shape[0] 
df = df.loc[df['word_bunch'] >= 5] 
deleted_cutoff = df.shape[0]
print("- cutoff data: {:,}({}%)".format(cutoff, round(cutoff/deleted_white*100, 2)))

print("- total processed data: {:,}".format(deleted_cutoff))
```

    - white space data: 0(0.0%)
    - cutoff data: 61,130(1.72%)
    - total processed data: 3,502,912



```python
df.to_csv('SNS_FULL_Dataset(í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬).csv', index=False)
```

